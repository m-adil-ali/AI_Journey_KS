{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = np.zeros((num_features, 1)) #dtype=np.float\n",
    "        self.bias = np.zeros(1,)  #dtype=np.float\n",
    "\n",
    "    def forward(self, x):\n",
    "        linear = np.dot(x, self.weights) + self.bias\n",
    "        predictions = np.where(linear > 0., 1, 0)\n",
    "        print('forward')\n",
    "        return predictions\n",
    "        \n",
    "    def backward(self, x, y):  \n",
    "        predictions = self.forward(x)\n",
    "        errors = y - predictions\n",
    "        print('back')\n",
    "        return errors\n",
    "        \n",
    "    def train(self, x, y, epochs):\n",
    "        for e in range(epochs):\n",
    "        \n",
    "            for i in range(y.shape[0]):\n",
    "                errors = self.backward(x[i].reshape(1, self.num_features), y[i]).reshape(-1)\n",
    "                self.weights += (errors * x[i]).reshape(self.num_features, 1)\n",
    "                self.bias += errors\n",
    "                print('epoch number', i )\n",
    "                \n",
    "    def evaluate(self, x, y):\n",
    "        predictions = self.forward(x).reshape(-1)\n",
    "        accuracy = np.sum(predictions == y) / y.shape[0]\n",
    "        print('eval')\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "back\n",
      "epoch number 0\n",
      "forward\n",
      "back\n",
      "epoch number 1\n",
      "forward\n",
      "back\n",
      "epoch number 2\n",
      "forward\n",
      "back\n",
      "epoch number 3\n",
      "forward\n",
      "eval\n",
      "Weights: [1. 1.]\n",
      "Bias: [0.]\n",
      "Accuracy: 2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample dataset (AND logic gate)\n",
    "# Features (inputs)\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "# Labels (outputs)\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "# Instantiate the Perceptron\n",
    "num_features = X.shape[1]  # Number of features (2 for the AND gate)\n",
    "perceptron = Perceptron(num_features)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "perceptron.train(X, y, epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = perceptron.evaluate(X, y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Weights:\", perceptron.weights.flatten())\n",
    "print(\"Bias:\", perceptron.bias.flatten())\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
